[supervisord]
nodaemon=true
logfile=/var/log/supervisor/supervisord.log

[program:postgresql]
command=/usr/lib/postgresql/16/bin/postgres -D /var/lib/postgresql/16/main -c config_file=/etc/postgresql/16/main/postgresql.conf
user=postgres
autostart=true
autorestart=true

[program:kafka-controller]
command=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/controller.properties
autostart=true
autorestart=true
environment=JAVA_HOME="/usr/lib/jvm/java-17-openjdk-amd64"

[program:kafka-broker]
# Delay so the controller is up before the broker tries to register
command=/bin/bash -c "sleep 8 && /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/broker.properties"
autostart=true
autorestart=true
startretries=5
environment=JAVA_HOME="/usr/lib/jvm/java-17-openjdk-amd64"

[program:init-topics]
# Runs once after broker is up, creates topics if they don't exist
command=/usr/local/bin/init-topics.sh
autostart=true
autorestart=false
startsecs=0

[program:airflow-webserver]
command=/bin/bash -c "sleep 20 && /opt/airflow-venv/bin/airflow api-server --port 8080"
autostart=true
autorestart=true
environment=AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="postgresql+psycopg2://airflow:airflow@localhost/airflow",AIRFLOW__CORE__EXECUTOR="LocalExecutor",AIRFLOW__CORE__AUTH_MANAGER="airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager"

[program:airflow-scheduler]
command=/bin/bash -c "sleep 20 && /opt/airflow-venv/bin/airflow scheduler"
autostart=true
autorestart=true
environment=AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="postgresql+psycopg2://airflow:airflow@localhost/airflow",AIRFLOW__CORE__EXECUTOR="LocalExecutor",AIRFLOW__CORE__AUTH_MANAGER="airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager"

[program:spark-master]
command=/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --webui-port 8081
autostart=true
autorestart=true
startsecs=5
environment=JAVA_HOME="/usr/lib/jvm/java-17-openjdk-amd64",SPARK_HOME="/opt/spark"

[program:spark-worker]
command=/bin/bash -c "sleep 10 && /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077"
autostart=true
autorestart=true
startretries=5
startsecs=15
environment=JAVA_HOME="/usr/lib/jvm/java-17-openjdk-amd64",SPARK_HOME="/opt/spark"